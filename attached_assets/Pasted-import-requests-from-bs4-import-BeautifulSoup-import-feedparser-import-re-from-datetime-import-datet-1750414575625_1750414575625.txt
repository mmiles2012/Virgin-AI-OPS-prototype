import requests
from bs4 import BeautifulSoup
import feedparser
import re
from datetime import datetime, timedelta
import json
from typing import List, Dict, Set
import time

class AviationNewsMonitor:
    def __init__(self):
        # Keywords for different categories affecting aviation
        self.keywords = {
            'geopolitical': [
                'sanctions', 'airspace', 'flight ban', 'diplomatic', 'embassy',
                'border', 'conflict', 'war', 'peace talks', 'treaty',
                'international relations', 'trade war', 'tariff', 'embargo'
            ],
            'aviation_events': [
                'aircraft', 'airline', 'airport', 'flight', 'aviation',
                'crash', 'incident', 'emergency landing', 'turbulence',
                'boeing', 'airbus', 'pilot', 'air traffic', 'runway',
                'maintenance', 'safety', 'faa', 'icao', 'air travel'
            ],
            'oil_energy': [
                'oil price', 'crude oil', 'fuel cost', 'jet fuel',
                'energy crisis', 'opec', 'petroleum', 'refinery',
                'fuel shortage', 'gas price', 'energy supply'
            ],
            'transport': [
                'transportation', 'logistics', 'supply chain', 'cargo',
                'freight', 'shipping', 'port', 'strike', 'union',
                'infrastructure', 'rail', 'trucking', 'maritime'
            ],
            'security': [
                'terrorist', 'terrorism', 'security threat', 'hijack',
                'bomb threat', 'screening', 'tsa', 'security alert',
                'suspicious activity', 'airport security', 'no-fly',
                'watchlist', 'cyber attack', 'drone threat'
            ]
        }
        
        # News sources RSS feeds and APIs
        self.news_sources = {
            'reuters': 'http://feeds.reuters.com/reuters/topNews',
            'bbc': 'http://feeds.bbci.co.uk/news/rss.xml',
            'aviation_week': 'https://aviationweek.com/rss.xml',
            'flight_global': 'https://www.flightglobal.com/rss/news/all-news/rss.xml',
            'ap_news': 'https://apnews.com/apf-topnews',
            'aviation_daily': 'https://aviationweek.com/daily-brief/rss.xml'
        }
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def fetch_rss_feed(self, url: str) -> List[Dict]:
        """Fetch and parse RSS feed"""
        try:
            feed = feedparser.parse(url)
            articles = []
            
            for entry in feed.entries[:20]:  # Limit to recent articles
                article = {
                    'title': entry.get('title', ''),
                    'description': entry.get('description', ''),
                    'link': entry.get('link', ''),
                    'published': entry.get('published', ''),
                    'source': url
                }
                articles.append(article)
            
            return articles
        except Exception as e:
            print(f"Error fetching RSS feed {url}: {e}")
            return []

    def calculate_relevance_score(self, text: str) -> Dict[str, int]:
        """Calculate relevance score for each category"""
        text_lower = text.lower()
        scores = {}
        
        for category, keywords in self.keywords.items():
            score = 0
            for keyword in keywords:
                # Count occurrences, with higher weight for exact matches
                if keyword in text_lower:
                    score += text_lower.count(keyword) * 2
                # Check for partial matches in word boundaries
                pattern = r'\b' + re.escape(keyword.split()[0]) + r'\b'
                matches = len(re.findall(pattern, text_lower))
                score += matches
            
            scores[category] = score
        
        return scores

    def is_aviation_relevant(self, article: Dict, min_score: int = 2) -> bool:
        """Check if article is relevant to aviation"""
        combined_text = f"{article['title']} {article['description']}"
        scores = self.calculate_relevance_score(combined_text)
        
        # Article is relevant if any category scores above threshold
        return any(score >= min_score for score in scores.values())

    def classify_article(self, article: Dict) -> Dict:
        """Classify article and add metadata"""
        combined_text = f"{article['title']} {article['description']}"
        scores = self.calculate_relevance_score(combined_text)
        
        # Find primary category (highest score)
        primary_category = max(scores.keys(), key=lambda k: scores[k])
        
        article['relevance_scores'] = scores
        article['primary_category'] = primary_category
        article['total_score'] = sum(scores.values())
        article['processed_at'] = datetime.now().isoformat()
        
        return article

    def fetch_all_news(self) -> List[Dict]:
        """Fetch news from all sources"""
        all_articles = []
        
        for source_name, url in self.news_sources.items():
            print(f"Fetching from {source_name}...")
            articles = self.fetch_rss_feed(url)
            
            for article in articles:
                article['source_name'] = source_name
                if self.is_aviation_relevant(article):
                    classified_article = self.classify_article(article)
                    all_articles.append(classified_article)
            
            time.sleep(1)  # Be respectful to servers
        
        return all_articles

    def filter_by_category(self, articles: List[Dict], category: str) -> List[Dict]:
        """Filter articles by primary category"""
        return [article for article in articles if article['primary_category'] == category]

    def filter_by_timeframe(self, articles: List[Dict], hours: int = 24) -> List[Dict]:
        """Filter articles by timeframe"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        filtered = []
        
        for article in articles:
            try:
                # Parse various date formats
                pub_date = None
                if article.get('published'):
                    # Try different date parsing approaches
                    for fmt in ['%a, %d %b %Y %H:%M:%S %Z', 
                              '%Y-%m-%dT%H:%M:%S%z',
                              '%a, %d %b %Y %H:%M:%S %z']:
                        try:
                            pub_date = datetime.strptime(article['published'], fmt)
                            break
                        except ValueError:
                            continue
                
                if pub_date and pub_date >= cutoff_time:
                    filtered.append(article)
                elif not pub_date:  # Include if we can't parse date
                    filtered.append(article)
                    
            except Exception as e:
                print(f"Date parsing error: {e}")
                filtered.append(article)  # Include on error
        
        return filtered

    def generate_summary_report(self, articles: List[Dict]) -> str:
        """Generate a summary report of relevant news"""
        if not articles:
            return "No aviation-relevant news found."
        
        # Sort by total relevance score
        articles.sort(key=lambda x: x['total_score'], reverse=True)
        
        report = f"Aviation News Summary - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        report += "=" * 60 + "\n\n"
        
        # Summary by category
        categories = {}
        for article in articles:
            cat = article['primary_category']
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(article)
        
        report += "CATEGORY BREAKDOWN:\n"
        for category, cat_articles in categories.items():
            report += f"  {category.title()}: {len(cat_articles)} articles\n"
        
        report += f"\nTOTAL RELEVANT ARTICLES: {len(articles)}\n\n"
        
        # Top articles
        report += "TOP RELEVANT ARTICLES:\n"
        report += "-" * 30 + "\n"
        
        for i, article in enumerate(articles[:10], 1):
            report += f"{i}. [{article['primary_category'].upper()}] "
            report += f"Score: {article['total_score']}\n"
            report += f"   Title: {article['title']}\n"
            report += f"   Source: {article['source_name']}\n"
            report += f"   Link: {article['link']}\n"
            if article['description']:
                desc = article['description'][:150] + "..." if len(article['description']) > 150 else article['description']
                report += f"   Summary: {desc}\n"
            report += "\n"
        
        return report

    def save_results(self, articles: List[Dict], filename: str = None):
        """Save results to JSON file"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'aviation_news_{timestamp}.json'
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(articles, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"Results saved to {filename}")

# Usage example
def main():
    monitor = AviationNewsMonitor()
    
    print("Fetching aviation-relevant news...")
    articles = monitor.fetch_all_news()
    
    if articles:
        # Filter to last 24 hours
        recent_articles = monitor.filter_by_timeframe(articles, hours=24)
        
        # Generate and print summary
        summary = monitor.generate_summary_report(recent_articles)
        print(summary)
        
        # Save results
        monitor.save_results(recent_articles)
        
        # Show category-specific results
        print("\nCategory-specific filtering examples:")
        for category in ['geopolitical', 'aviation_events', 'security']:
            cat_articles = monitor.filter_by_category(recent_articles, category)
            print(f"{category.title()}: {len(cat_articles)} articles")
    
    else:
        print("No relevant articles found.")

if __name__ == "__main__":
    main()